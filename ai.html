<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> 
<html xmlns="http://www.w3.org/1999/xhtml"> 
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Blog</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.css" rel="stylesheet">

    <!-- Add custom CSS here -->
    <link href="css/simple-sidebar.css" rel="stylesheet">
    <link href="css/navbar.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="/css/base.css"/>
<!--    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet"> -->

                <script src="build/three.min.js"></script>
                <script src="js/loaders/ColladaLoader.js"></script>
                <script src="js/Detector.js"></script>
                <script src="js/OrbitControls.js"></script>
                <script src="js/jquery.js"></script>
                <script src="https://raw.github.com/sole/tween.js/master/build/tween.min.js"></script>
  </head>

  <body>
  
    <div id="wrapper">
      
  <div class="navbar"> 
  <div class="IEfix"><div class="container"></div>
    <a href="index.html"><div class="nav">Home</div></a>
  	<a href="brain.html"><div class="nav">BrainExplorer</div></a>
  	<a href="motorfunction.html"><div class="nav">BrainExplorer Pt. 2</div></a>
  	<a href="about.html"><div class="nav">Blog</div></a>
  </div>
  </div>
</div>

<div class="centered" style="font-family: Times New Roman">
  How do we make machines understand music the way we do?
  <br>
  <strong>Level 1: Recommendation Systems</strong>
  <br>
  Suppose you're a computer working for Spotify. The user is listening to a specific song, maybe "Grenade" by Bruno Mars.
  <br>
  Now, I want you to figure out five recommendations to give to the user. There are a ton of ways you could do this. Right now,
  many recommendation systems look at multiple other users who also listened to "Grenade", and looked at the songs they consumed
  right after that. Then it makes recommendations based on those other songs.
  While that may work, what about looking into the actual music itself and finding musical similarities between songs? The user
  may be quite inclined to like songs of a similar rhythm, in a similar key, etc...
  <br>
  This is an example of a central question in a field called music information retrieval, which is focused on extracting
  data from audio signals.
  </div>
    </body>
    <div class="centered" style="font-family: Times New Roman">
    How can machines understand music?
For my independent project freshman year, I wanted to see if a machine could learn how to classify songs. This could be used as a recommendation system for music streaming services such as Spotify. <br> I developed a neural network that classifies different types of music into seven genres: rock, hip-hop, pop, classical, blues, country, and jazz. <br> The network analyzes just over 300 songs extracted from the Million Songs Dataset, and it uses the loudness, key, time signature, tempo, and mode to put each song into a category. It isn’t terribly accurate (60%), and my computer freezes when I run it--but hey, it’s a learning experience, right? 
<br>
In this write-up, I will explore this problem, what I learned from it and why I think neural networks will never take over the world! <br>
If we’re talking about people, how someone understands music varies according to their personality, history, and loads of other factors. For example, someone born in the 1980’s may classify Avril Lavigne songs as alternative rock, while someone born in the 2000’s may think it is punk. This reflects how they learned about music in the first place.
Neural networks are interesting because they model the learning process. We don’t tell the network what is the difference between a rap song and a hip-hop. Instead, the neural network figures it out on its own via a trial-and-error method: making a hypothesis, double-checking, and adjusting the weights and running its inputs through the net until it’s satisfied with its results using calculus. It’s how I used to learn as a child, jumping off tables until I determined just how painful it was, touching, feeling, exploring the world and drawing my own conclusions. There’s something adorable about a computer being creative, like a dolphin painting with a brush in its mouth.
	Now for the technical part! I used a supervised learning algorithm to train a two-layer neural net: the output from the first layer was the input for the second layer. The second layer then produced an output of the song’s probability of belonging to each class, which was double-checked with the correct answer. (In an unsupervised learning model, the net wouldn’t know the correct answer.) The overall motive for the neural net is to find a function which will reliably take the input X to the correct output Y. Below is a diagram showing the different functions I used.
*insert pic*

First in goes the input. This is a set of features: loudness, key, time signature, tempo, and mode. These features are unique for each song and are what are being used to put it in one of seven genres.
The first layer is called a ReLU, or a Rectified Linear Unit. My reason for adding it in here is to introduce nonlinearity into our function predictions. If the function that we are trying to predict was linear, then we would not need this. The ReLU takes in a set of features, and for each feature x outputs f(x) = max(weight_of_feature * x + b, 0). The weight of feature is randomized at first, then adjusted later on. The graph is as shown below:

	    <img src="pic_mountain.jpg" alt="Mountain View" style="width:304px;height:228px;">

	    
Notice how similar this is to the graph f = e^x!
So the output from the ReLU then is inputted into the softmax layer. 

What this does is take your feature set and output a matrix of the probailities of your song belonging to each class, so in this case it would output a 7 x 1 matrix. It’s a generalization of logistic regression, if you’ve heard of that before. If you want to go more in depth, here is a good link which mathematically explains softmax regression: http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/.

After your input has completed the neural network, you look at your 7 x 1 matrix and choose the class with the highest probability. Then you look at the actual answer! You probably won’t get it right on the first time, so use a cost function to compute the error between your answer and the right one. Then we use calculus to propagate that error back through the layer and adjust the weights in each layer accordingly. (This is called backpropagation.)
I think the most difficult part of machine learning is choosing the right data to put into your feature set. For example, suppose you want to classify plants to divide them into different beds. If you used something like color, that may not be too useful, right? However, if you used features like soil conditions, or maybe the right time of the year for planting, then your results might be a little more optimal for the task you’re attempting. This is the reason why I think humans are never going to completely disappear from the scene of machine learning; prioritizing data is one of the most difficult machine learning tasks.
  </div>

  </html>
